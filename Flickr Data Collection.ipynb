{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3784acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flickrapi\n",
    "import webbrowser\n",
    "\n",
    "# API keys\n",
    "API_KEY = \"db4c4d646adf494007498f2ffde82ea6\"\n",
    "API_SECRET = \"26cad008ca7b167f\"\n",
    "\n",
    "# Code for authenticating the Flickr API\n",
    "flickr = flickrapi.FlickrAPI(API_KEY, API_SECRET)\n",
    "\n",
    "if not flickr.token_valid(perms=\"read\"):\n",
    "    flickr.get_request_token(oauth_callback=\"oob\")\n",
    "    authorize_url = flickr.auth_url(perms=\"read\")\n",
    "    webbrowser.open_new_tab(authorize_url)\n",
    "    verifier = str(input(\"Verifier code: \"))\n",
    "    flickr.get_access_token(verifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0bebec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "# Get list of photos\n",
    "curr_time_utc = datetime.datetime.now(datetime.timezone.utc)\n",
    "five_years_ago_timestamp = (curr_time_utc - datetime.timedelta(days=3*365)).timestamp()\n",
    "photo_data_filename = \"photo_data.csv\"\n",
    "west_coast_bbox = \"-124.763068,32.534231,-114.134458,49.002494\"\n",
    "east_coast_bbox = \"-87.634938,24.523096,-66.949895,47.459686\"\n",
    "attributes = [\"date_upload\", \"date_taken\", \"last_update\", \"owner_name\", \"geo\", \"views\"]\n",
    "extracted_attributes = [\"dateupload\", \"datetaken\", \"lastupdate\", \"ownername\",\n",
    "                        \"latitude\", \"longitude\", \"views\"]\n",
    "from os.path import exists\n",
    "if not exists(photo_data_filename):\n",
    "    photos_dict = {}\n",
    "    for attribute in extracted_attributes:\n",
    "        photos_dict[attribute] = []\n",
    "    num_pages = 600\n",
    "    safe_search_level = 1\n",
    "    has_geo = 1\n",
    "    for i in range(1, num_pages + 1):\n",
    "        try:\n",
    "            photos_metadata = flickr.photos.search(format=\"parsed-json\", min_upload_date=five_years_ago_timestamp,\n",
    "                                                   min_taken_date=five_years_ago_timestamp, bbox=west_coast_bbox,\n",
    "                                                   safe_search=safe_search_level, has_geo=has_geo,\n",
    "                                                   extras=\",\".join(attributes), page=i)\n",
    "            photos_metadata2 = flickr.photos.search(format=\"parsed-json\", min_upload_date=five_years_ago_timestamp,\n",
    "                                                   min_taken_date=five_years_ago_timestamp, bbox=east_coast_bbox,\n",
    "                                                   safe_search=safe_search_level, has_geo=has_geo,\n",
    "                                                   extras=\",\".join(attributes), page=i)\n",
    "        except flickr.FlickrError:\n",
    "            continue\n",
    "        for j in range(len(photos_metadata[\"photos\"][\"photo\"])):\n",
    "            for attribute in extracted_attributes:\n",
    "                photos_dict[attribute].append(photos_metadata[\"photos\"][\"photo\"][j][attribute])\n",
    "        for j in range(len(photos_metadata2[\"photos\"][\"photo\"])):\n",
    "            for attribute in extracted_attributes:\n",
    "                photos_dict[attribute].append(photos_metadata2[\"photos\"][\"photo\"][j][attribute])\n",
    "    photo_data = pd.DataFrame.from_dict(photos_dict)\n",
    "    photo_data = photo_data.sample(frac=1).reset_index(drop=True)\n",
    "    photo_data.to_csv(photo_data_filename, index=False)\n",
    "else:\n",
    "    photo_data = pd.read_csv(photo_data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477826b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n"
     ]
    }
   ],
   "source": [
    "import reverse_geocoder as rg\n",
    "\n",
    "loc_data_sample_filename = \"location_data.csv\"\n",
    "if not exists(loc_data_sample_filename):\n",
    "    place_data = photo_data[[\"latitude\", \"longitude\"]].apply(pd.to_numeric)\n",
    "    place_data.groupby([\"latitude\", \"longitude\"])\n",
    "    coordinates = [(row[\"latitude\"], row[\"longitude\"]) for _, row in place_data.iterrows()]\n",
    "    loc_dict = {\"latitude\": [], \"longitude\": [], \"city\": [], \"county\": [], \"state\": []}\n",
    "    locations = rg.search(coordinates)\n",
    "    for loc in locations:\n",
    "        loc_dict[\"latitude\"].append(loc[\"lat\"])\n",
    "        loc_dict[\"longitude\"].append(loc[\"lon\"])\n",
    "        loc_dict[\"city\"].append(loc[\"name\"])\n",
    "        loc_dict[\"county\"].append(loc[\"admin2\"])\n",
    "        loc_dict[\"state\"].append(loc[\"admin1\"])\n",
    "    loc_data = pd.DataFrame.from_dict(loc_dict)\n",
    "    loc_data.to_csv(loc_data_sample_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b1658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
