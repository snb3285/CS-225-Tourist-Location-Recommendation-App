{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3784acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flickrapi\n",
    "import webbrowser\n",
    "\n",
    "# API keys\n",
    "API_KEY = \"db4c4d646adf494007498f2ffde82ea6\"\n",
    "API_SECRET = \"26cad008ca7b167f\"\n",
    "\n",
    "# Code for authenticating the Flickr API\n",
    "flickr = flickrapi.FlickrAPI(API_KEY, API_SECRET)\n",
    "\n",
    "if not flickr.token_valid(perms=\"read\"):\n",
    "    flickr.get_request_token(oauth_callback=\"oob\")\n",
    "    authorize_url = flickr.auth_url(perms=\"read\")\n",
    "    webbrowser.open_new_tab(authorize_url)\n",
    "    verifier = str(input(\"Verifier code: \"))\n",
    "    flickr.get_access_token(verifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0bebec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Get list of photos\n",
    "curr_time_utc = datetime.datetime.now(datetime.timezone.utc)\n",
    "timestamps = []\n",
    "time_utc = curr_time_utc\n",
    "# Number of 3 month intervals in the last 5 years\n",
    "three_month_intervals = 20\n",
    "for i in range(three_month_intervals):\n",
    "    time_utc = time_utc - datetime.timedelta(days=90)\n",
    "    timestamps.append(time_utc.timestamp())\n",
    "spring_photos_data_filename = \"spring_photos_data.csv\"\n",
    "summer_photos_data_filename = \"summer_photos_data.csv\"\n",
    "fall_photos_data_filename = \"fall_photos_data.csv\"\n",
    "winter_photos_data_filename = \"winter_photos_data.csv\"\n",
    "west_coast_bbox = \"-124.763068,32.534231,-114.134458,49.002494\"\n",
    "east_coast_bbox = \"-87.634938,24.523096,-66.949895,47.459686\"\n",
    "attributes = [\"date_upload\", \"date_taken\", \"last_update\", \"owner_name\", \"geo\", \"tags\", \"views\"]\n",
    "extracted_attributes = [\"id\", \"dateupload\", \"datetaken\", \"lastupdate\", \"ownername\",\n",
    "                        \"latitude\", \"longitude\", \"tags\", \"views\"]\n",
    "\n",
    "spring_photos_dict = {}\n",
    "summer_photos_dict = {}\n",
    "fall_photos_dict = {}\n",
    "winter_photos_dict = {}\n",
    "for attribute in extracted_attributes:\n",
    "    spring_photos_dict[attribute] = []\n",
    "    summer_photos_dict[attribute] = []\n",
    "    fall_photos_dict[attribute] = []\n",
    "    winter_photos_dict[attribute] = []\n",
    "# Approximately 4000 unique photos per query, divided by 250 per page\n",
    "num_pages = 16\n",
    "safe_search_level = 1\n",
    "has_geo = 1\n",
    "\n",
    "for i in range(len(timestamps)):\n",
    "    min_timestamp = timestamps[i]\n",
    "    if i == 0:\n",
    "        max_timestamp = curr_time_utc.timestamp()\n",
    "    else:\n",
    "        max_timestamp = timestamps[i - 1]\n",
    "    for j in range(1, num_pages + 1):\n",
    "        try:\n",
    "            photos_metadata = flickr.photos.search(format=\"parsed-json\", min_upload_date=min_timestamp,\n",
    "                                                   max_upload_date=max_timestamp, bbox=west_coast_bbox,\n",
    "                                                   safe_search=safe_search_level, has_geo=has_geo,\n",
    "                                                   extras=\",\".join(attributes), page=j)\n",
    "            photos_metadata2 = flickr.photos.search(format=\"parsed-json\", min_upload_date=min_timestamp,\n",
    "                                                   max_upload_date=max_timestamp, bbox=east_coast_bbox,\n",
    "                                                   safe_search=safe_search_level, has_geo=has_geo,\n",
    "                                                   extras=\",\".join(attributes), page=j)\n",
    "        except flickr.FlickrError:\n",
    "            continue\n",
    "        for photo in photos_metadata[\"photos\"][\"photo\"]:\n",
    "            iso_date_str = photo[\"datetaken\"].split(\" \")[0]\n",
    "            iso_date = datetime.date.fromisoformat(iso_date_str)\n",
    "            if 3 <= iso_date.month <= 5:    \n",
    "                for attribute in extracted_attributes:\n",
    "                    spring_photos_dict[attribute].append(photo[attribute])\n",
    "            elif 6 <= iso_date.month <= 8:\n",
    "                for attribute in extracted_attributes:\n",
    "                    summer_photos_dict[attribute].append(photo[attribute])\n",
    "            elif 9 <= iso_date.month <= 11:\n",
    "                for attribute in extracted_attributes:\n",
    "                    fall_photos_dict[attribute].append(photo[attribute])\n",
    "            elif iso_date.month == 12 or 1 <= iso_date.month <= 2:\n",
    "                for attribute in extracted_attributes:\n",
    "                    winter_photos_dict[attribute].append(photo[attribute])\n",
    "        for photo in photos_metadata2[\"photos\"][\"photo\"]:\n",
    "            iso_date_str = photo[\"datetaken\"].split(\" \")[0]\n",
    "            iso_date = datetime.date.fromisoformat(iso_date_str)\n",
    "            if 3 <= iso_date.month <= 5:    \n",
    "                for attribute in extracted_attributes:\n",
    "                    spring_photos_dict[attribute].append(photo[attribute])\n",
    "            elif 6 <= iso_date.month <= 8:\n",
    "                for attribute in extracted_attributes:\n",
    "                    summer_photos_dict[attribute].append(photo[attribute])\n",
    "            elif 9 <= iso_date.month <= 11:\n",
    "                for attribute in extracted_attributes:\n",
    "                    fall_photos_dict[attribute].append(photo[attribute])\n",
    "            elif iso_date.month == 12 or 1 <= iso_date.month <= 2:\n",
    "                for attribute in extracted_attributes:\n",
    "                    winter_photos_dict[attribute].append(photo[attribute])\n",
    "                \n",
    "spring_photos_data = pd.DataFrame.from_dict(spring_photos_dict)\n",
    "spring_photos_data = spring_photos_data.drop_duplicates(subset=\"id\", keep=\"first\")\n",
    "spring_photos_data = spring_photos_data.sample(frac=1).reset_index(drop=True)\n",
    "spring_photos_data.to_csv(spring_photos_data_filename, index=False)\n",
    "summer_photos_data = pd.DataFrame.from_dict(summer_photos_dict)\n",
    "summer_photos_data = summer_photos_data.drop_duplicates(subset=\"id\", keep=\"first\")\n",
    "summer_photos_data = summer_photos_data.sample(frac=1).reset_index(drop=True)\n",
    "summer_photos_data.to_csv(summer_photos_data_filename, index=False)\n",
    "fall_photos_data = pd.DataFrame.from_dict(fall_photos_dict)\n",
    "fall_photos_data = fall_photos_data.drop_duplicates(subset=\"id\", keep=\"first\")\n",
    "fall_photos_data = fall_photos_data.sample(frac=1).reset_index(drop=True)\n",
    "fall_photos_data.to_csv(fall_photos_data_filename, index=False)\n",
    "winter_photos_data = pd.DataFrame.from_dict(winter_photos_dict)\n",
    "winter_photos_data = winter_photos_data.drop_duplicates(subset=\"id\", keep=\"first\")\n",
    "winter_photos_data = winter_photos_data.sample(frac=1).reset_index(drop=True)\n",
    "winter_photos_data.to_csv(winter_photos_data_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477826b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n"
     ]
    }
   ],
   "source": [
    "import reverse_geocoder as rg\n",
    "spring_photos_data = pd.read_csv(spring_photos_data_filename)\n",
    "summer_photos_data = pd.read_csv(summer_photos_data_filename)\n",
    "fall_photos_data = pd.read_csv(fall_photos_data_filename)\n",
    "winter_photos_data = pd.read_csv(winter_photos_data_filename)\n",
    "\n",
    "spring_places_data = spring_photos_data[[\"latitude\", \"longitude\"]].apply(pd.to_numeric)\n",
    "summer_places_data = summer_photos_data[[\"latitude\", \"longitude\"]].apply(pd.to_numeric)\n",
    "fall_places_data = fall_photos_data[[\"latitude\", \"longitude\"]].apply(pd.to_numeric)\n",
    "winter_places_data = winter_photos_data[[\"latitude\", \"longitude\"]].apply(pd.to_numeric)\n",
    "\n",
    "spring_places_coordinates = [(row[\"latitude\"], row[\"longitude\"]) for _, row in spring_places_data.iterrows()]\n",
    "summer_places_coordinates = [(row[\"latitude\"], row[\"longitude\"]) for _, row in summer_places_data.iterrows()]\n",
    "fall_places_coordinates = [(row[\"latitude\"], row[\"longitude\"]) for _, row in fall_places_data.iterrows()]\n",
    "winter_places_coordinates = [(row[\"latitude\"], row[\"longitude\"]) for _, row in winter_places_data.iterrows()]\n",
    "\n",
    "spring_loc_dict = {\"city\": [], \"county\": [], \"state\": []}\n",
    "summer_loc_dict = {\"city\": [], \"county\": [], \"state\": []}\n",
    "fall_loc_dict = {\"city\": [], \"county\": [], \"state\": []}\n",
    "winter_loc_dict = {\"city\": [], \"county\": [], \"state\": []}\n",
    "\n",
    "spring_locations = rg.search(spring_places_coordinates)\n",
    "summer_locations = rg.search(summer_places_coordinates)\n",
    "fall_locations = rg.search(fall_places_coordinates)\n",
    "winter_locations = rg.search(winter_places_coordinates)\n",
    "\n",
    "for loc in spring_locations:\n",
    "    spring_loc_dict[\"city\"].append(loc[\"name\"])\n",
    "    spring_loc_dict[\"county\"].append(loc[\"admin2\"])\n",
    "    spring_loc_dict[\"state\"].append(loc[\"admin1\"])\n",
    "for loc in summer_locations:\n",
    "    summer_loc_dict[\"city\"].append(loc[\"name\"])\n",
    "    summer_loc_dict[\"county\"].append(loc[\"admin2\"])\n",
    "    summer_loc_dict[\"state\"].append(loc[\"admin1\"])\n",
    "for loc in fall_locations:\n",
    "    fall_loc_dict[\"city\"].append(loc[\"name\"])\n",
    "    fall_loc_dict[\"county\"].append(loc[\"admin2\"])\n",
    "    fall_loc_dict[\"state\"].append(loc[\"admin1\"])\n",
    "for loc in winter_locations:\n",
    "    winter_loc_dict[\"city\"].append(loc[\"name\"])\n",
    "    winter_loc_dict[\"county\"].append(loc[\"admin2\"])\n",
    "    winter_loc_dict[\"state\"].append(loc[\"admin1\"])\n",
    "\n",
    "spring_photos_data[\"city\"] = spring_loc_dict[\"city\"]\n",
    "spring_photos_data[\"county\"] = spring_loc_dict[\"county\"]\n",
    "spring_photos_data[\"state\"] = spring_loc_dict[\"state\"]\n",
    "spring_photos_data.to_csv(spring_photos_data_filename, index=False)\n",
    "summer_photos_data[\"city\"] = summer_loc_dict[\"city\"]\n",
    "summer_photos_data[\"county\"] = summer_loc_dict[\"county\"]\n",
    "summer_photos_data[\"state\"] = summer_loc_dict[\"state\"]\n",
    "summer_photos_data.to_csv(summer_photos_data_filename, index=False)\n",
    "fall_photos_data[\"city\"] = fall_loc_dict[\"city\"]\n",
    "fall_photos_data[\"county\"] = fall_loc_dict[\"county\"]\n",
    "fall_photos_data[\"state\"] = fall_loc_dict[\"state\"]\n",
    "fall_photos_data.to_csv(fall_photos_data_filename, index=False)\n",
    "winter_photos_data[\"city\"] = winter_loc_dict[\"city\"]\n",
    "winter_photos_data[\"county\"] = winter_loc_dict[\"county\"]\n",
    "winter_photos_data[\"state\"] = winter_loc_dict[\"state\"]\n",
    "winter_photos_data.to_csv(winter_photos_data_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b1658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
